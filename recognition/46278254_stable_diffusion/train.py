# ==== import from package ==== #
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from tqdm import tqdm
from einops import reduce
from torch.utils.data import TensorDataset, DataLoader
from tqdm import tqdm

# ==== import from this folder ==== #
from model_VAE import VQVAE, VAE
from util import reset_dir, compact_large_image
from model_diffusion import LatentDiffusionModel

DEVICE = torch.device("cuda")
print("DEVICE:", DEVICE)

# Fixed the random seed for reproducibiilty
torch.manual_seed(0)

# Select loaded model
mode = 'VAE'
load_epoch = 31

# Load pre-train model
vae = torch.load(f'model_ckpt/{mode}/epoch_AE_{load_epoch}.pt')
vae.eval()

# Get latent set. The latent set should be generated by collected_latents.
latent_set = torch.load(f'collected_latents/{mode}_{load_epoch}.pt')

# Define visalize folder
vis_folder = f'visualize/stable_diffusion_{mode}_vis'
reset_dir(vis_folder)

# Define checkpoint folder
reset_dir(f'model_ckpt/stable_diffusion_{mode}')

# Try to normalize latents with conditions
with torch.no_grad():
    latents, z_indices = latent_set.tensors[0], latent_set.tensors[1]
    if mode == 'VAE':
        # In 'VAE' mode, reparameterization latents into a space that decoder familiar with.
        # TODO: Reparameterization has noise. (mean + exp(log_exp) * randn )
        # Therefore we can add different noise when training DDPM.
        latents, _ = vae.reparameterization(latents)

    # The distribution of latents we get is very chaotic, and its harmful to DDPM noise.
    # To avoid this issue, we'll normalize the latent into (-1, 1) before doing DDPM.
    normalized_latents = latents
    latents_mean = torch.zeros(
        [32, *latents.shape[1:]]).to(device=latents.device)
    latents_std = torch.zeros_like(latents_mean)
    for cur_z_idx in range(0, 32):
        chosen = z_indices == cur_z_idx

        # Note that mean & std is not mean & std. It's move and scaling factor.
        latents_mean[cur_z_idx] = reduce(
            latents[chosen], 'n c h w -> 1 c h w', 'min')
        latents_std[cur_z_idx] = reduce(
            latents[chosen], 'n c h w -> 1 c h w', 'max') - latents_mean[cur_z_idx]
        normalized_latents[chosen] = (
            latents[chosen] - latents_mean[cur_z_idx]) / latents_std[cur_z_idx]
        # Move range 0 ~ 1 to -1, 1
        normalized_latents[chosen] = 2 * (normalized_latents[chosen] - 0.5)

# Change tensors into dataloader
print("Latent shape:", normalized_latents.shape)
dataset = TensorDataset(normalized_latents, z_indices)
dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)

# Setup configs about diffusion model
net = LatentDiffusionModel(in_channels=latents.shape[1], ch=32).to(DEVICE)
criteria = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)


def test_epoch(net, folder):
    with torch.no_grad():
        # We only sample 6 images (and each images contain 32 idx)
        sample_n = 6
        for cur_idx in range(sample_n):
            # Define condition from 0 to 31 (z-index of brain).
            cond = torch.arange(0, 32, device=DEVICE, dtype=torch.long)
            # Get sample latent from network
            sample_latent = net.sample_with_cond(
                (1, latents.shape[1], 16, 16), cond)
            # move -1 ~ 1) to 0 ~ 1
            sample_latent = sample_latent * 0.5 + 0.5
            # move 0 ~ 1 to original latent space
            sample_latent = sample_latent * latents_std + latents_mean

            # In VQVAE, we need quantize vector before decode.
            if mode == 'VQVAE':
                quant, diff_loss, ind = vae.quantize(sample_latent)
                sample_img = vae.decode(quant, cond)
            elif mode == 'VAE':
                sample_img = vae.decode(sample_latent, cond)

            # Save the result
            sample_img = compact_large_image(sample_img.cpu(), HZ=4, WZ=8)
            plt.imsave(f'{folder}/{cur_idx}.png',
                       sample_img[0] * 0.5 + 0.5, cmap='gray')

total_epoch = 301
for epoch in range(total_epoch):
    total_loss, total_len = 0, 0
    for latent, zs in tqdm(dataloader, total=len(dataloader)):
        latent = latent.cuda()
        batch_size = latent.shape[0]

        # Clean the gradients
        optimizer.zero_grad()

        # Random generate time in DDPM.
        t = torch.randint(0, net.T, size=(batch_size, )).cuda()
        latent_noise, noise = net.get_noise(latent, t)
        predicted_noise = net.forward(latent_noise, t, zs)

        # Using L1-loss / MAE to measure latents distance
        loss = torch.abs(noise.contiguous() - predicted_noise.contiguous())
        loss = torch.sum(loss) / batch_size

        # Update network weights
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_len += 1

    # Testing every 25 epochs
    if epoch % 25 == 0 or epoch == total_epoch-1:
        # Save the model
        torch.save(net, f'model_ckpt/stable_diffusion_{mode}/UNet_{epoch}.pt')
        folder = f'{vis_folder}/epoch_{epoch}'
        reset_dir(folder)
        test_epoch(net, folder)

    # Print loss after training
    print(f"epoch {epoch:4d}, loss {total_loss / total_len:.5f}")
