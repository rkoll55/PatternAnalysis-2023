{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Input: batch size=2, dimension=4\n",
    "BN = nn.BatchNorm2d(4, momentum=0.001)\n",
    "LN = nn.LayerNorm([4, 2, 2])\n",
    "IN = nn.InstanceNorm2d(4, momentum=0.001, track_running_stats=True)\n",
    "GN = nn.GroupNorm(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 4, 2, 2])\n",
      "tensor([0.2167, 0.7709])\n",
      "tensor([1.0249, 2.0181, 2.9922, 3.9332])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    bns = []\n",
    "    lns = []\n",
    "    ins = []\n",
    "    gns = []\n",
    "    # Input: batch size=2, channel=4\n",
    "    Xs = []\n",
    "    for _ in range(1000):\n",
    "        X = torch.randn(2, 4, 2, 2) * torch.Tensor([1, 2, 3, 4]).view([1, 4, 1, 1])\n",
    "        X = X + torch.Tensor([[[[0.25]]], [[[0.75]]]])\n",
    "        Xs.append(X)\n",
    "        bns.append(BN(X))\n",
    "        lns.append(LN(X))\n",
    "        ins.append(IN(X))\n",
    "        gns.append(GN(X))\n",
    "    \n",
    "    # X[i,j,_,_] = N(i=0:0.25, i=1:0.75, j)\n",
    "    from einops import rearrange\n",
    "    Xs = torch.cat(Xs)\n",
    "    Xs = rearrange(Xs, '(N B) C H W -> N B C H W', B=2)\n",
    "    print(Xs.shape)\n",
    "    # N(0, 1) * a + b = N(b, a)\n",
    "    print(torch.mean(Xs, dim=(0, 2, 3, 4)))\n",
    "    print(torch.std(Xs, dim=(0, 1, 3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Normalization\n",
    "> [Group Normalization, ECCV 2018](https://arxiv.org/abs/1803.08494)\n",
    "\n",
    "![](../report_imgs/group_normalization.png)\n",
    "\n",
    "Normalization: A method to train model faster and more stable through normalization of tinputs by re-centering and re-scaling.\n",
    "* Batch normalization: Normalization for each channel.\n",
    "* Layer normalization: Normalization for each sample.\n",
    "* Instance normalization: Normalization for each sample and each channel.\n",
    "* Group normalization: Normalization for each sample group.\n",
    "\n",
    "> Note: If batch size is large enough, the performance: BN > GN > LN > IN \n",
    "> However, BN has GPU memory issue and cannot set large batch size sometimes. \n",
    "> Thus, we do GN in this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN: tensor([0.5023, 0.4710, 0.4848, 0.5362]) tensor([1.0352, 2.0148, 2.9973, 3.9475])\n",
      "BN result:\n",
      "\n",
      "tensor([[-0.2155, -0.2184, -0.0668, -0.0943],\n",
      "        [ 0.2823,  0.1797,  0.0206,  0.0361]])\n",
      "tensor([[0.9713, 0.9612, 0.9779, 0.9821],\n",
      "        [0.9870, 0.9552, 1.0062, 0.9939]])\n"
     ]
    }
   ],
   "source": [
    "# Running Stats: (1, 4)\n",
    "# Mean: (0.25 + 0.75) / 2, std should = [1, 2, 3, 4]\n",
    "print(\"BN:\", BN.running_mean, BN.running_var**0.5)\n",
    "def result(x):\n",
    "    x = torch.concat([b.view([-1, *b.shape]) for b in x])\n",
    "    return torch.mean(x, 0)[:, :, 0, 0], torch.std(x, 0)[:, :, 0, 0]\n",
    "\n",
    "print(\"BN result:\\n\", *result(bns), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: tensor([0.3266, 0.3093, 0.3428, 0.2990]) tensor([0.9990, 1.6975, 2.4882, 3.2176])\n",
      "IN result:\n",
      "\n",
      "tensor([[-0.0158,  0.0414, -0.0042, -0.0302],\n",
      "        [ 0.0101,  0.0496, -0.0134,  0.0412]])\n",
      "tensor([[1.0015, 0.9890, 0.9876, 1.0147],\n",
      "        [1.0100, 1.0073, 1.0017, 1.0115]])\n"
     ]
    }
   ],
   "source": [
    "# Running Stats: (2, 4)\n",
    "# Normalize for each sample -> all output should be (0, 1)\n",
    "print(\"IN:\", IN.running_mean, IN.running_var**0.5)\n",
    "print(\"IN result:\\n\", *result(ins), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LN result:\n",
      "\n",
      "tensor([[ 0.0315, -0.0710,  0.0216,  0.0093],\n",
      "        [ 0.0028,  0.0141, -0.0813, -0.0391]])\n",
      "tensor([[0.4771, 0.7857, 1.0952, 1.3753],\n",
      "        [0.4890, 0.7932, 1.1020, 1.3691]])\n"
     ]
    }
   ],
   "source": [
    "# Running Stats: (2, 1)\n",
    "# Output Mean: Should all be 0. (Sample 1=0.25-0.25, Sample 2=0.75-0.75)\n",
    "# Output Std: each sample has same variance\n",
    "print(\"LN result:\\n\", *result(lns), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GN result:\n",
      "\n",
      "tensor([[-0.0160,  0.0487, -0.0040, -0.0190],\n",
      "        [ 0.0212,  0.0353,  0.0173,  0.0181]])\n",
      "tensor([[0.7633, 1.1811, 0.8882, 1.0921],\n",
      "        [0.7640, 1.2026, 0.8888, 1.1119]])\n"
     ]
    }
   ],
   "source": [
    "# Group = 1 -> Layer Norm\n",
    "# Group = 4 -> Instance Norm\n",
    "# Group = 2 -> Split 2 blocks and do Layer Norm\n",
    "print(\"GN result:\\n\", *result(gns), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
